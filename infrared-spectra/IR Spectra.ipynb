{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Medium post: https://medium.com/@kevin_guo/infrared-spectra-classification-experiment-94457e925549"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/untitled1/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-118f1595486a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmolecules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Molecules: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmolecules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'labels'"
     ]
    }
   ],
   "source": [
    "# Load IR data and split into train/test\n",
    "\n",
    "import keras\n",
    "import random\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "data_path = 'data/'\n",
    "\n",
    "aldehydes = np.array([712, 177, 527, 261, 7860, 6561, 8063, 11552, 7284, 6184, 7359, 12417, 31245, # monofunctionalized\n",
    "                      756, 7897, 751, # alcohol\n",
    "                      7860, 10964, 12524, # dicarbonyl \n",
    "                      75, 188982, # amino \n",
    "                      527448, 18635, 18635, # thiol\n",
    "                      123114, 13002, 7847, 20138, 643950, 5280971, 9543055]) # sterically strained / conjugation\n",
    "\n",
    "other_carbonyls = np.array([284, 767, 176, # acids\n",
    "                            8025, 8857]) # esters\n",
    "\n",
    "non_carbonyls = np.array([79015, 702, 887, 962, # alcohols\n",
    "                          10795, 8028, 8029, # ethers\n",
    "                          6329, 878, 6343, 7848, 6058, 6329, 674, # other heteroatomic functionality\n",
    "                          313, # inorganic\n",
    "                          297, 6324, 8252, 6334, 8255, 6326, 6335, 1146])# unfunctionalized (un)saturated aliphatic compounds\n",
    "\n",
    "\n",
    "files = [f.split('.')[0] for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "molecules = list(map(int, filter(lambda f: f != '',files)))\n",
    "\n",
    "print('Molecules: ', molecules)\n",
    "print('')\n",
    "\n",
    "ald_perm = np.random.permutation(aldehydes) # deterministically chosen since random seed is set above\n",
    "carbonyl_perm = np.random.permutation(other_carbonyls)\n",
    "other_perm = np.random.permutation(non_carbonyls)\n",
    "\n",
    "train_mol_ids = list(ald_perm[len(aldehydes) // 5:]) + list(\n",
    "    carbonyl_perm[len(carbonyl_perm) // 5:]) + list(other_perm[len(other_perm) // 5:])\n",
    "\n",
    "raw_train_X = [] # list of lists of (peak, intensity)\n",
    "raw_train_y = [] # 0: non-carbonyl, 1: aldehyde, 2: acid/ester\n",
    "raw_test_X = []\n",
    "raw_test_y = []\n",
    "\n",
    "for mol_id in molecules:\n",
    "    with open(data_path + str(mol_id) + '.dat') as f:\n",
    "        mol_data = []\n",
    "        for line in f:\n",
    "            peak, intensity = line.split()\n",
    "            if mol_id in aldehydes:\n",
    "                y = 1\n",
    "            elif mol_id in other_carbonyls:\n",
    "                y = 2\n",
    "            else:\n",
    "                y = 0\n",
    "            mol_data.append((peak, intensity))\n",
    "        if mol_id in train_mol_ids:\n",
    "            raw_train_X.append(mol_data)\n",
    "            raw_train_y.append(y)\n",
    "        else:\n",
    "            raw_test_X.append(mol_data)\n",
    "            raw_test_y.append(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "911 molecular infrared spectra loaded.\n",
      "729 training examples.\n",
      "182 test examples.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import random\n",
    "import h5py\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "functional_groups = ['unfunctionalized alkane', 'alkene', 'alkyne',\n",
    "                     'alcohol', 'ether', 'amine',\n",
    "                     'aldehyde', 'ketone', 'carboxylic acid', 'ester', 'amide']\n",
    "\n",
    "load_only_monofunctional = True \n",
    "group_ester_acid = False \n",
    "\n",
    "data_path = 'data/'\n",
    "\n",
    "molecules = []\n",
    "labels = []\n",
    "\n",
    "with open('data/labels.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        nist_id = line.split()[0]\n",
    "        label = list(map(int, line.split()[1:]))\n",
    "        if load_only_monofunctional:\n",
    "            if len(label) > 1:\n",
    "                continue\n",
    "            else: label = label[0]\n",
    "        h5f = h5py.File('data/spectra/' + nist_id + '.h5', 'r')\n",
    "        wavenumbers = np.array(h5f['x'])\n",
    "        intensities = np.array(h5f['y'])\n",
    "        h5f.close()\n",
    "        mol = []\n",
    "        for wn, intens in zip(wavenumbers, intensities):\n",
    "            #if intens > 10:\n",
    "            mol.append((wn, intens))\n",
    "        if np.max(intensities) != 100:\n",
    "            #print('something went wrong...') # TODO: fix this\n",
    "            continue\n",
    "        molecules.append(mol)\n",
    "        labels.append(label)\n",
    "\n",
    "if group_ester_acid:\n",
    "    labels = list(map(lambda l: 8 if l == 9 else l, labels))\n",
    "        \n",
    "perm = np.random.permutation(np.arange(len(molecules)))\n",
    "\n",
    "raw_train_X = []\n",
    "raw_train_y = []\n",
    "raw_test_X = []\n",
    "raw_test_y = []\n",
    "\n",
    "for i in range(len(perm) // 5): # split 80:20\n",
    "    raw_test_X.append(molecules[i])\n",
    "    raw_test_y.append(labels[i])\n",
    "while i < len(perm) - 1:\n",
    "    i += 1\n",
    "    raw_train_X.append(molecules[i])\n",
    "    raw_train_y.append(labels[i])\n",
    "    \n",
    "print(len(molecules), 'molecular infrared spectra loaded.')\n",
    "print(len(raw_train_X), 'training examples.')\n",
    "print(len(raw_test_X), 'test examples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Augmenting raw data\n",
    "\n",
    "# # Data augmentation\n",
    "\n",
    "# # TODO: introduce small changes in intensity/wavenumber\n",
    "# # Paper on data augmentation for infrared spectra https://arxiv.org/pdf/1710.01927.pdf\n",
    "\n",
    "# num_augments = 50 # number of times to augment all data\n",
    "# intens_noise = 15 # std; absolute difference in intensity\n",
    "# wn_noise = 10 # std; absolute difference in wavenumbers\n",
    "# peak_noise = (1/250, (10, 10)) # (probability of a random peak appearing, intensity mean/std)\n",
    "\n",
    "# unaugmented_train_X = raw_train_X.copy()\n",
    "# unaugmented_test_X = raw_test_X.copy()\n",
    "\n",
    "# def augment(x):\n",
    "#     \"\"\" Augment data for the given sample. \"\"\"\n",
    "#     aug = []\n",
    "#     noise = np.random.normal([0, 0], [wn_noise, intens_noise], (len(x), 2))\n",
    "#     for (noise_wn, noise_intens), (peak, intens) in zip(x, noise):\n",
    "#         aug.append((peak + noise_wn, intens + noise_intens))\n",
    "#     new_peaks = np.random.binomial(1, peak_noise[0], 2500).nonzero() + 1000 # only generate from 1000 - 3500 cm-1\n",
    "#     intensities = np.random.normal(*peak_noise[1], len(new_peaks))\n",
    "#     for wn, intens in zip(new_peaks, intensities):\n",
    "#         aug.append((wn, intens))\n",
    "#     return aug\n",
    "\n",
    "# for _ in range(num_augments):\n",
    "#     for x in unaugmented_train_X:\n",
    "#         raw_train_X.append(augment(x))\n",
    "#     for x in unaugmented_test_X:\n",
    "#         raw_test_X.append(augment(x))\n",
    "        \n",
    "# print('Total Training Samples: ', len(raw_train_X))\n",
    "# print('Total Testing Samples: ', len(raw_test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "911 examples successfully vectorized into 700 dimensional vectors.\n"
     ]
    }
   ],
   "source": [
    "# Vectorizing raw data\n",
    "\n",
    "# classify_carbonyls = False # if True, will group all carbonyls together\n",
    "dim = 700 # number of dimensions in vectorization; default is every 5 cm-1\n",
    "\n",
    "# train_y = keras.utils.to_categorical(map(lambda y: 1 if y == 1 else 0, raw_train_y))\n",
    "# test_y = keras.utils.to_categorical(map(lambda y: 1 if y == 1 else 0, raw_test_y))\n",
    "# if classify_carbonyls:\n",
    "#     train_y = keras.utils.to_categorical(map(lambda y: 1 if y == 1 or y == 2 else 0, raw_train_y))\n",
    "#     test_y = keras.utils.to_categorical(map(lambda y: 1 if y == 1 or y == 2 else 0, raw_test_y))\n",
    "\n",
    "train_y = keras.utils.to_categorical(raw_train_y)\n",
    "test_y = keras.utils.to_categorical(raw_test_y)\n",
    "\n",
    "step = 3500 / (dim)\n",
    "\n",
    "def vectorize(peaks):\n",
    "    \"\"\" Converts IR data into vector. Only strongest peak in each interval will be kept. \"\"\"\n",
    "    vec = np.zeros(dim)\n",
    "    for wavenumber, intensity in peaks:\n",
    "        index = int((wavenumber - 500) // step) # data will range from 500 to 4000\n",
    "        vec[index] = max(intensity, vec[index])\n",
    "    return vec\n",
    "\n",
    "train_X = np.array(list(map(vectorize, raw_train_X)))\n",
    "test_X = np.array(list(map(vectorize, raw_test_X)))\n",
    "\n",
    "print(len(train_X) + len(test_X), 'examples successfully vectorized into', dim, 'dimensional vectors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model construction\n",
    "\n",
    "from keras import models, layers\n",
    "\n",
    "convolution_distance = 40 # in wavenumbers\n",
    "kernel_size = int(convolution_distance // step)\n",
    "\n",
    "model = models.Sequential()\n",
    "#model.add(layers.Conv1D(32, kernel_size, activation='relu'))\n",
    "# model.add(layers.Conv1D(64, convolution_distance // step, activation='relu'))\n",
    "# model.add(layers.MaxPooling1D(convolution_distance // step))\n",
    "# model.add(layers.Flatten())\n",
    "model.add(layers.Dense(600, activation='relu', input_shape = (dim,)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(300, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.Dense(100, activation='relu'))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(len(train_y[0]), activation='softplus'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 729 samples, validate on 182 samples\n",
      "Epoch 1/10\n",
      "729/729 [==============================] - 1s 1ms/step - loss: 1.5842 - categorical_accuracy: 0.5075 - val_loss: 1.5564 - val_categorical_accuracy: 0.5220\n",
      "Epoch 2/10\n",
      "729/729 [==============================] - 1s 1ms/step - loss: 1.6009 - categorical_accuracy: 0.5350 - val_loss: 1.5707 - val_categorical_accuracy: 0.5165\n",
      "Epoch 3/10\n",
      "729/729 [==============================] - 1s 1ms/step - loss: 1.6714 - categorical_accuracy: 0.5487 - val_loss: 1.5050 - val_categorical_accuracy: 0.5165\n",
      "Epoch 4/10\n",
      "729/729 [==============================] - 1s 1ms/step - loss: 1.4877 - categorical_accuracy: 0.5144 - val_loss: 1.4561 - val_categorical_accuracy: 0.5440\n",
      "Epoch 5/10\n",
      "729/729 [==============================] - 1s 1ms/step - loss: 1.7276 - categorical_accuracy: 0.5638 - val_loss: 1.5156 - val_categorical_accuracy: 0.4670\n",
      "Epoch 6/10\n",
      "729/729 [==============================] - 1s 1ms/step - loss: 1.5417 - categorical_accuracy: 0.5405 - val_loss: 1.5895 - val_categorical_accuracy: 0.4945\n",
      "Epoch 7/10\n",
      "729/729 [==============================] - 1s 1ms/step - loss: 1.5832 - categorical_accuracy: 0.5501 - val_loss: 1.5523 - val_categorical_accuracy: 0.5495\n",
      "Epoch 8/10\n",
      "729/729 [==============================] - 1s 1ms/step - loss: 1.4260 - categorical_accuracy: 0.5748 - val_loss: 1.4289 - val_categorical_accuracy: 0.5824\n",
      "Epoch 9/10\n",
      "729/729 [==============================] - 1s 1ms/step - loss: 1.4758 - categorical_accuracy: 0.5528 - val_loss: 1.4525 - val_categorical_accuracy: 0.5440\n",
      "Epoch 10/10\n",
      "729/729 [==============================] - 1s 1ms/step - loss: 1.4342 - categorical_accuracy: 0.5981 - val_loss: 1.4412 - val_categorical_accuracy: 0.6099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x136c7b160>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "# model.fit(train_X, train_y, batch_size=16, epochs=25, validation_data=(test_X, test_y), shuffle=True) # gets to 67% with adamax\n",
    "# model.fit(train_X, train_y, batch_size=8, epochs=25, validation_data=(test_X, test_y), shuffle=True) # gets to 65% with adamax\n",
    "model.fit(train_X, train_y, batch_size=8, epochs=10, validation_data=(test_X, test_y), shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137.0\n",
      "1716.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  10.76,\n",
       "        13.38,  15.75,  21.11,  32.06,  32.78,  27.8 ,  18.72,  11.82,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,  13.83,  14.44,  13.16,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,  11.34,  12.01,  11.46,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  10.92,  14.55,\n",
       "        18.01,  23.59,  52.42,  84.14, 100.  ,  97.99,  77.01,  41.94,\n",
       "        25.77,  14.83,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,  10.51,\n",
       "        12.89,  14.28,  14.26,  12.2 ,   0.  ,  10.83,  12.98,  13.87,\n",
       "        23.8 ,  37.79,  42.63,  35.12,  18.36,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "         0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((1700-500) // step)\n",
    "print(step * 139 + 500)\n",
    "train_X[10][140]\n",
    "train_X[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
